{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1BFkEeaxAnBhj6HA0FrOdqkMC-jOrhQti","authorship_tag":"ABX9TyNAy/AddxOeNtgsEHTn9oiV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"ciIALr3euy-v","executionInfo":{"status":"ok","timestamp":1707551970605,"user_tz":-330,"elapsed":395,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense"]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Sherlock Holmes Dataset.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()"],"metadata":{"id":"jIsdRUEvv_Ex","executionInfo":{"status":"ok","timestamp":1707551971633,"user_tz":-330,"elapsed":637,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Tokenizer process\n","tokenizer = Tokenizer()\n","#fit\n","tokenizer.fit_on_texts([text])\n","#assign length of word index\n","total_words = len(tokenizer.word_index) + 1"],"metadata":{"id":"6Kqo6zj6wcR6","executionInfo":{"status":"ok","timestamp":1707551971634,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#chek the tokens\n","tokenizer.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gkj2--fswhMe","executionInfo":{"status":"ok","timestamp":1707551971635,"user_tz":-330,"elapsed":24,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"cf7938a3-c7b1-4704-9397-30634d39f6a5"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'the': 1,\n"," 'and': 2,\n"," 'i': 3,\n"," 'to': 4,\n"," 'of': 5,\n"," 'a': 6,\n"," 'in': 7,\n"," 'that': 8,\n"," 'it': 9,\n"," 'he': 10,\n"," 'you': 11,\n"," 'was': 12,\n"," 'his': 13,\n"," 'is': 14,\n"," 'my': 15,\n"," 'have': 16,\n"," 'as': 17,\n"," 'with': 18,\n"," 'had': 19,\n"," 'which': 20,\n"," 'at': 21,\n"," 'for': 22,\n"," 'but': 23,\n"," 'me': 24,\n"," 'not': 25,\n"," 'be': 26,\n"," 'we': 27,\n"," 'from': 28,\n"," 'there': 29,\n"," 'this': 30,\n"," 'said': 31,\n"," 'upon': 32,\n"," 'so': 33,\n"," 'holmes': 34,\n"," 'him': 35,\n"," 'her': 36,\n"," 'she': 37,\n"," \"'\": 38,\n"," 'very': 39,\n"," 'your': 40,\n"," 'been': 41,\n"," 'all': 42,\n"," 'on': 43,\n"," 'no': 44,\n"," 'what': 45,\n"," 'one': 46,\n"," 'then': 47,\n"," 'were': 48,\n"," 'by': 49,\n"," 'are': 50,\n"," 'an': 51,\n"," 'would': 52,\n"," 'out': 53,\n"," 'when': 54,\n"," 'up': 55,\n"," 'man': 56,\n"," 'could': 57,\n"," 'has': 58,\n"," 'do': 59,\n"," 'into': 60,\n"," 'mr': 61,\n"," 'who': 62,\n"," 'little': 63,\n"," 'will': 64,\n"," 'if': 65,\n"," 'some': 66,\n"," 'now': 67,\n"," 'see': 68,\n"," 'down': 69,\n"," 'should': 70,\n"," 'our': 71,\n"," 'or': 72,\n"," 'they': 73,\n"," 'may': 74,\n"," 'well': 75,\n"," 'am': 76,\n"," 'us': 77,\n"," 'over': 78,\n"," 'more': 79,\n"," 'think': 80,\n"," 'room': 81,\n"," 'know': 82,\n"," 'shall': 83,\n"," 'about': 84,\n"," 'can': 85,\n"," 'before': 86,\n"," 'must': 87,\n"," 'only': 88,\n"," 'come': 89,\n"," 'than': 90,\n"," 'did': 91,\n"," 'time': 92,\n"," 'two': 93,\n"," 'other': 94,\n"," 'came': 95,\n"," 'them': 96,\n"," 'door': 97,\n"," 'back': 98,\n"," 'how': 99,\n"," 'good': 100,\n"," 'here': 101,\n"," 'any': 102,\n"," 'face': 103,\n"," 'might': 104,\n"," 'just': 105,\n"," 'matter': 106,\n"," 'house': 107,\n"," 'much': 108,\n"," 'hand': 109,\n"," 'case': 110,\n"," 'way': 111,\n"," 'where': 112,\n"," 'night': 113,\n"," 'yes': 114,\n"," 'heard': 115,\n"," 'such': 116,\n"," 'made': 117,\n"," 'nothing': 118,\n"," 'however': 119,\n"," 'found': 120,\n"," 'away': 121,\n"," 'day': 122,\n"," 'never': 123,\n"," 'quite': 124,\n"," 'morning': 125,\n"," 'own': 126,\n"," 'go': 127,\n"," 'after': 128,\n"," 'sherlock': 129,\n"," 'right': 130,\n"," 'their': 131,\n"," 'like': 132,\n"," 'tell': 133,\n"," 'last': 134,\n"," 'say': 135,\n"," 'left': 136,\n"," 'through': 137,\n"," 'saw': 138,\n"," 'most': 139,\n"," 'yet': 140,\n"," 'side': 141,\n"," 'asked': 142,\n"," 'eyes': 143,\n"," 'long': 144,\n"," 'took': 145,\n"," 'miss': 146,\n"," 'its': 147,\n"," 'once': 148,\n"," 'first': 149,\n"," 'street': 150,\n"," 'too': 151,\n"," 'every': 152,\n"," 'watson': 153,\n"," 'round': 154,\n"," 'young': 155,\n"," 'st': 156,\n"," 'still': 157,\n"," 'these': 158,\n"," 'find': 159,\n"," 'take': 160,\n"," 'small': 161,\n"," 'thought': 162,\n"," 'myself': 163,\n"," 'sir': 164,\n"," 'few': 165,\n"," 'light': 166,\n"," 'oh': 167,\n"," 'until': 168,\n"," 'off': 169,\n"," 'without': 170,\n"," 'himself': 171,\n"," 'hands': 172,\n"," 'make': 173,\n"," 'business': 174,\n"," 'father': 175,\n"," 'seen': 176,\n"," 'old': 177,\n"," 'window': 178,\n"," 'lady': 179,\n"," 'look': 180,\n"," 'three': 181,\n"," 'ever': 182,\n"," 'even': 183,\n"," 'friend': 184,\n"," 'let': 185,\n"," 'cried': 186,\n"," 'seemed': 187,\n"," 'again': 188,\n"," 'head': 189,\n"," 'went': 190,\n"," 'having': 191,\n"," 'put': 192,\n"," 'why': 193,\n"," 'done': 194,\n"," 'while': 195,\n"," 'those': 196,\n"," 'something': 197,\n"," 'doubt': 198,\n"," 'remarked': 199,\n"," 'open': 200,\n"," 'rather': 201,\n"," 'years': 202,\n"," 'though': 203,\n"," 'name': 204,\n"," 'indeed': 205,\n"," 'chair': 206,\n"," 'half': 207,\n"," 'perhaps': 208,\n"," 'get': 209,\n"," 'woman': 210,\n"," 'between': 211,\n"," 'give': 212,\n"," 'great': 213,\n"," 'course': 214,\n"," 'always': 215,\n"," 'mind': 216,\n"," 'enough': 217,\n"," 'knew': 218,\n"," 'end': 219,\n"," 'answered': 220,\n"," 'same': 221,\n"," 'far': 222,\n"," 'sat': 223,\n"," 'looking': 224,\n"," 'place': 225,\n"," 'table': 226,\n"," 'dear': 227,\n"," 'wife': 228,\n"," 'got': 229,\n"," 'police': 230,\n"," 'against': 231,\n"," 'also': 232,\n"," 'really': 233,\n"," 'red': 234,\n"," 'looked': 235,\n"," 'black': 236,\n"," 'better': 237,\n"," 'anything': 238,\n"," 'turned': 239,\n"," 'cannot': 240,\n"," 'behind': 241,\n"," 'told': 242,\n"," 'hardly': 243,\n"," 'hat': 244,\n"," 'front': 245,\n"," 'brought': 246,\n"," 'possible': 247,\n"," 'home': 248,\n"," 'understand': 249,\n"," 'life': 250,\n"," 'leave': 251,\n"," 'within': 252,\n"," 'work': 253,\n"," 'help': 254,\n"," 'thing': 255,\n"," 'both': 256,\n"," 'already': 257,\n"," 'suddenly': 258,\n"," 'strange': 259,\n"," 'gave': 260,\n"," 'words': 261,\n"," 'son': 262,\n"," 'whole': 263,\n"," 'fire': 264,\n"," 'point': 265,\n"," 'paper': 266,\n"," 'being': 267,\n"," 'papers': 268,\n"," 'minutes': 269,\n"," 'hair': 270,\n"," 'clear': 271,\n"," 'money': 272,\n"," 'wish': 273,\n"," 'gone': 274,\n"," 'under': 275,\n"," 'call': 276,\n"," 'sure': 277,\n"," 'whether': 278,\n"," \"'i\": 279,\n"," 'mrs': 280,\n"," 'set': 281,\n"," 'yourself': 282,\n"," 'certainly': 283,\n"," 'gentleman': 284,\n"," 'many': 285,\n"," 'pray': 286,\n"," 'another': 287,\n"," 'lay': 288,\n"," 'baker': 289,\n"," 'passed': 290,\n"," 'london': 291,\n"," 'large': 292,\n"," 'days': 293,\n"," 'five': 294,\n"," 'dark': 295,\n"," 'word': 296,\n"," 'met': 297,\n"," 'since': 298,\n"," 'whom': 299,\n"," 'does': 300,\n"," 'soon': 301,\n"," 'lord': 302,\n"," 'bed': 303,\n"," 'simon': 304,\n"," 'less': 305,\n"," 'during': 306,\n"," 'men': 307,\n"," 'four': 308,\n"," 'interest': 309,\n"," 'evening': 310,\n"," 'save': 311,\n"," 'across': 312,\n"," 'note': 313,\n"," 'lestrade': 314,\n"," 'returned': 315,\n"," 'read': 316,\n"," 'opened': 317,\n"," 'least': 318,\n"," 'strong': 319,\n"," 'among': 320,\n"," 'story': 321,\n"," 'stood': 322,\n"," 'country': 323,\n"," 'together': 324,\n"," 'believe': 325,\n"," 'facts': 326,\n"," 'doctor': 327,\n"," 'question': 328,\n"," 'ask': 329,\n"," 'moment': 330,\n"," 'none': 331,\n"," 'waiting': 332,\n"," 'fellow': 333,\n"," 'rucastle': 334,\n"," 'felt': 335,\n"," 'either': 336,\n"," \"o'clock\": 337,\n"," 'entered': 338,\n"," 'sitting': 339,\n"," 'use': 340,\n"," 'rushed': 341,\n"," 'mccarthy': 342,\n"," 'each': 343,\n"," 'crime': 344,\n"," 'singular': 345,\n"," 'part': 346,\n"," 'corner': 347,\n"," 'seven': 348,\n"," 'given': 349,\n"," 'hear': 350,\n"," 'hour': 351,\n"," 'else': 352,\n"," 'laid': 353,\n"," 'road': 354,\n"," 'going': 355,\n"," 'sound': 356,\n"," 'client': 357,\n"," 'best': 358,\n"," 'able': 359,\n"," 'became': 360,\n"," 'near': 361,\n"," 'instant': 362,\n"," 'hope': 363,\n"," 'forward': 364,\n"," 'used': 365,\n"," \"'you\": 366,\n"," 'stone': 367,\n"," 'family': 368,\n"," 'companion': 369,\n"," 'new': 370,\n"," 'heavy': 371,\n"," \"it's\": 372,\n"," 'turn': 373,\n"," 'several': 374,\n"," 'letter': 375,\n"," 'ran': 376,\n"," 'cut': 377,\n"," 'rooms': 378,\n"," 'threw': 379,\n"," 'true': 380,\n"," 'imagine': 381,\n"," 'six': 382,\n"," \"don't\": 383,\n"," 'past': 384,\n"," 'dr': 385,\n"," 'white': 386,\n"," 'known': 387,\n"," 'year': 388,\n"," 'floor': 389,\n"," 'hard': 390,\n"," 'ten': 391,\n"," 'obvious': 392,\n"," 'inspector': 393,\n"," 'coronet': 394,\n"," 'late': 395,\n"," 'manner': 396,\n"," 'ago': 397,\n"," 'death': 398,\n"," 'want': 399,\n"," 'feet': 400,\n"," 'coat': 401,\n"," 'taken': 402,\n"," 'station': 403,\n"," 'walked': 404,\n"," 'fear': 405,\n"," 'seems': 406,\n"," 'cry': 407,\n"," 'coming': 408,\n"," 'ah': 409,\n"," 'lamp': 410,\n"," 'spoke': 411,\n"," 'things': 412,\n"," 'marriage': 413,\n"," 'lost': 414,\n"," 'dress': 415,\n"," 'appeared': 416,\n"," 'present': 417,\n"," 'absolutely': 418,\n"," 'air': 419,\n"," 'above': 420,\n"," 'goose': 421,\n"," 'colonel': 422,\n"," 'blue': 423,\n"," 'visitor': 424,\n"," 'deep': 425,\n"," 'alone': 426,\n"," 'rose': 427,\n"," 'called': 428,\n"," 'letters': 429,\n"," 'cab': 430,\n"," 'drove': 431,\n"," 'god': 432,\n"," 'dressed': 433,\n"," 'remember': 434,\n"," 'mine': 435,\n"," 'reason': 436,\n"," 'keep': 437,\n"," 'held': 438,\n"," 'office': 439,\n"," 'sister': 440,\n"," 'week': 441,\n"," 'led': 442,\n"," 'bell': 443,\n"," 'steps': 444,\n"," 'address': 445,\n"," 'followed': 446,\n"," 'king': 447,\n"," 'photograph': 448,\n"," 'married': 449,\n"," 'second': 450,\n"," 'beside': 451,\n"," 'quick': 452,\n"," 'windows': 453,\n"," 'people': 454,\n"," 'began': 455,\n"," 'john': 456,\n"," 'chance': 457,\n"," 'easy': 458,\n"," 'heart': 459,\n"," 'fact': 460,\n"," 'square': 461,\n"," 'headed': 462,\n"," 'nature': 463,\n"," 'attention': 464,\n"," 'eye': 465,\n"," 'step': 466,\n"," 'outside': 467,\n"," 'cases': 468,\n"," 'likely': 469,\n"," 'twenty': 470,\n"," 'started': 471,\n"," 'anyone': 472,\n"," 'struck': 473,\n"," 'silence': 474,\n"," 'thank': 475,\n"," 'grey': 476,\n"," 'ready': 477,\n"," 'girl': 478,\n"," 'glancing': 479,\n"," 'passage': 480,\n"," 'sprang': 481,\n"," 'ground': 482,\n"," 'daughter': 483,\n"," 'bring': 484,\n"," 'next': 485,\n"," 'lane': 486,\n"," 'whose': 487,\n"," 'maid': 488,\n"," 'pocket': 489,\n"," 'standing': 490,\n"," 'sort': 491,\n"," 'poor': 492,\n"," 'town': 493,\n"," 'happened': 494,\n"," 'idea': 495,\n"," 'breakfast': 496,\n"," 'holder': 497,\n"," 'clair': 498,\n"," 'mystery': 499,\n"," 'cold': 500,\n"," 'position': 501,\n"," 'high': 502,\n"," 'clothes': 503,\n"," 'observed': 504,\n"," 'because': 505,\n"," 'carried': 506,\n"," 'person': 507,\n"," 'glanced': 508,\n"," 'hurried': 509,\n"," 'carriage': 510,\n"," 'drawn': 511,\n"," 'husband': 512,\n"," 'kind': 513,\n"," 'closed': 514,\n"," 'short': 515,\n"," 'bird': 516,\n"," 'hosmer': 517,\n"," 'occurred': 518,\n"," 'seeing': 519,\n"," 'mary': 520,\n"," 'order': 521,\n"," 'ha': 522,\n"," 'interesting': 523,\n"," 'doing': 524,\n"," 'important': 525,\n"," 'quiet': 526,\n"," 'need': 527,\n"," 'train': 528,\n"," 'afraid': 529,\n"," 'considerable': 530,\n"," 'body': 531,\n"," 'city': 532,\n"," 'sight': 533,\n"," 'points': 534,\n"," 'thin': 535,\n"," 'danger': 536,\n"," 'wedding': 537,\n"," 'public': 538,\n"," 'hunter': 539,\n"," 'account': 540,\n"," 'problem': 541,\n"," 'shown': 542,\n"," 'fashion': 543,\n"," 'matters': 544,\n"," 'written': 545,\n"," 'peculiar': 546,\n"," 'boy': 547,\n"," 'england': 548,\n"," 'character': 549,\n"," 'voice': 550,\n"," 'caught': 551,\n"," 'speak': 552,\n"," 'secret': 553,\n"," 'laughed': 554,\n"," 'close': 555,\n"," 'remarkable': 556,\n"," 'quietly': 557,\n"," 'towards': 558,\n"," 'mean': 559,\n"," 'drive': 560,\n"," 'cause': 561,\n"," 'turner': 562,\n"," 'hours': 563,\n"," 'fresh': 564,\n"," 'ourselves': 565,\n"," 'showed': 566,\n"," 'safe': 567,\n"," 'wilson': 568,\n"," 'advertisement': 569,\n"," 'earth': 570,\n"," 'experience': 571,\n"," 'everything': 572,\n"," 'opinion': 573,\n"," 'talk': 574,\n"," 'windibank': 575,\n"," 'mother': 576,\n"," 'adventure': 577,\n"," 'placed': 578,\n"," 'excellent': 579,\n"," 'extraordinary': 580,\n"," 'finally': 581,\n"," 'figure': 582,\n"," 'observe': 583,\n"," 'someone': 584,\n"," 'simple': 585,\n"," 'hall': 586,\n"," 'means': 587,\n"," 'sent': 588,\n"," 'hundred': 589,\n"," 'single': 590,\n"," 'slowly': 591,\n"," 'sign': 592,\n"," 'line': 593,\n"," 'lodge': 594,\n"," 'suppose': 595,\n"," 'child': 596,\n"," 'reached': 597,\n"," 'details': 598,\n"," 'wait': 599,\n"," 'others': 600,\n"," 'direction': 601,\n"," 'dead': 602,\n"," 'box': 603,\n"," 'return': 604,\n"," 'rest': 605,\n"," 'finger': 606,\n"," 'court': 607,\n"," 'effect': 608,\n"," 'colour': 609,\n"," 'advice': 610,\n"," 'pipe': 611,\n"," 'silent': 612,\n"," 'angel': 613,\n"," 'stepfather': 614,\n"," 'pool': 615,\n"," 'frank': 616,\n"," 'k': 617,\n"," 'neville': 618,\n"," 'stoner': 619,\n"," 'love': 620,\n"," 'remained': 621,\n"," 'glad': 622,\n"," 'itself': 623,\n"," 'almost': 624,\n"," 'laughing': 625,\n"," 'times': 626,\n"," 'serious': 627,\n"," 'gold': 628,\n"," 'news': 629,\n"," 'bedroom': 630,\n"," 'garden': 631,\n"," 'listened': 632,\n"," \"'and\": 633,\n"," 'nor': 634,\n"," 'afterwards': 635,\n"," 'entirely': 636,\n"," 'fell': 637,\n"," 'lips': 638,\n"," 'bright': 639,\n"," 'water': 640,\n"," 'low': 641,\n"," 'locked': 642,\n"," 'happy': 643,\n"," 'along': 644,\n"," \"i'll\": 645,\n"," 'james': 646,\n"," 'arthur': 647,\n"," 'league': 648,\n"," 'thumb': 649,\n"," 'dreadful': 650,\n"," 'appears': 651,\n"," 'glance': 652,\n"," 'sit': 653,\n"," 'boots': 654,\n"," 'pay': 655,\n"," 'morrow': 656,\n"," 'afternoon': 657,\n"," 'pulled': 658,\n"," \"won't\": 659,\n"," 'meet': 660,\n"," \"holmes'\": 661,\n"," 'drew': 662,\n"," 'making': 663,\n"," 'ring': 664,\n"," 'seem': 665,\n"," 'weeks': 666,\n"," 'foot': 667,\n"," 'wooden': 668,\n"," 'instantly': 669,\n"," 'surprised': 670,\n"," 'feel': 671,\n"," 'hatherley': 672,\n"," 'evidence': 673,\n"," 'miles': 674,\n"," 'innocent': 675,\n"," 'feeling': 676,\n"," 'geese': 677,\n"," 'boscombe': 678,\n"," 'irene': 679,\n"," 'adler': 680,\n"," 'machine': 681,\n"," 'lit': 682,\n"," 'twice': 683,\n"," 'chamber': 684,\n"," 'kindly': 685,\n"," 'double': 686,\n"," 'show': 687,\n"," 'explain': 688,\n"," 'yours': 689,\n"," 'importance': 690,\n"," 'examined': 691,\n"," 'brown': 692,\n"," 'comes': 693,\n"," 'sharp': 694,\n"," 'shoulders': 695,\n"," 'impression': 696,\n"," 'appearance': 697,\n"," 'broad': 698,\n"," 'trust': 699,\n"," 'confess': 700,\n"," 'surprise': 701,\n"," 'majesty': 702,\n"," 'mad': 703,\n"," 'lock': 704,\n"," 'arrived': 705,\n"," 'dropped': 706,\n"," 'whispered': 707,\n"," 'taking': 708,\n"," 'centre': 709,\n"," 'determined': 710,\n"," 'change': 711,\n"," 'key': 712,\n"," 'turning': 713,\n"," 'company': 714,\n"," 'events': 715,\n"," 'shook': 716,\n"," 'full': 717,\n"," 'third': 718,\n"," 'smiling': 719,\n"," 'yard': 720,\n"," 'dog': 721,\n"," 'sudden': 722,\n"," 'pale': 723,\n"," 'cleared': 724,\n"," 'dressing': 725,\n"," 'world': 726,\n"," 'armchair': 727,\n"," 'fancy': 728,\n"," 'walk': 729,\n"," 'caused': 730,\n"," 'german': 731,\n"," 'therefore': 732,\n"," 'excuse': 733,\n"," 'thirty': 734,\n"," 'certain': 735,\n"," 'view': 736,\n"," 'deal': 737,\n"," 'object': 738,\n"," 'probably': 739,\n"," 'witness': 740,\n"," 'whatever': 741,\n"," 'neither': 742,\n"," 'blood': 743,\n"," 'waited': 744,\n"," 'later': 745,\n"," 'engaged': 746,\n"," 'care': 747,\n"," 'slight': 748,\n"," 'cellar': 749,\n"," 'live': 750,\n"," 'says': 751,\n"," \"didn't\": 752,\n"," 'answer': 753,\n"," 'claim': 754,\n"," 'force': 755,\n"," 'yellow': 756,\n"," 'wrong': 757,\n"," 'coroner': 758,\n"," 'terrible': 759,\n"," 'truth': 760,\n"," 'openshaw': 761,\n"," 'toller': 762,\n"," 'band': 763,\n"," 'noble': 764,\n"," 'society': 765,\n"," 'pass': 766,\n"," 'swiftly': 767,\n"," 'top': 768,\n"," 'thick': 769,\n"," 'lying': 770,\n"," 'eight': 771,\n"," 'received': 772,\n"," 'wrote': 773,\n"," 'scene': 774,\n"," 'glass': 775,\n"," 'continued': 776,\n"," 'stairs': 777,\n"," 'bad': 778,\n"," 'pushed': 779,\n"," 'absolute': 780,\n"," 'promise': 781,\n"," 'difficult': 782,\n"," 'follow': 783,\n"," 'private': 784,\n"," 'result': 785,\n"," 'monday': 786,\n"," 'features': 787,\n"," 'wall': 788,\n"," 'evidently': 789,\n"," 'arms': 790,\n"," 'church': 791,\n"," 'shot': 792,\n"," \"'the\": 793,\n"," 'run': 794,\n"," 'smoke': 795,\n"," 'broke': 796,\n"," 'shoulder': 797,\n"," 'walking': 798,\n"," 'impossible': 799,\n"," 'age': 800,\n"," 'affair': 801,\n"," 'assistant': 802,\n"," 'common': 803,\n"," \"'oh\": 804,\n"," 'died': 805,\n"," 'clay': 806,\n"," 'sum': 807,\n"," 'bank': 808,\n"," 'amid': 809,\n"," 'early': 810,\n"," 'clearly': 811,\n"," 'nine': 812,\n"," 'presence': 813,\n"," 'darkness': 814,\n"," \"man's\": 815,\n"," 'reading': 816,\n"," 'uncle': 817,\n"," 'friends': 818,\n"," 'hotel': 819,\n"," 'professional': 820,\n"," 'frightened': 821,\n"," 'bent': 822,\n"," 'envelope': 823,\n"," 'den': 824,\n"," 'roylott': 825,\n"," 'ventilator': 826,\n"," 'scandal': 827,\n"," 'copper': 828,\n"," 'power': 829,\n"," 'master': 830,\n"," 'signs': 831,\n"," 'spoken': 832,\n"," 'deduce': 833,\n"," 'inside': 834,\n"," 'throwing': 835,\n"," 'example': 836,\n"," 'houses': 837,\n"," 'tried': 838,\n"," 'send': 839,\n"," 'wood': 840,\n"," 'situation': 841,\n"," 'expected': 842,\n"," 'faced': 843,\n"," 'running': 844,\n"," 'usual': 845,\n"," 'different': 846,\n"," 'nearly': 847,\n"," 'raise': 848,\n"," 'self': 849,\n"," 'besides': 850,\n"," \"he's\": 851,\n"," 'yesterday': 852,\n"," 'months': 853,\n"," 'slipped': 854,\n"," 'heavily': 855,\n"," 'ross': 856,\n"," 'building': 857,\n"," 'middle': 858,\n"," 'knowledge': 859,\n"," 'edge': 860,\n"," 'clue': 861,\n"," 'start': 862,\n"," 'missing': 863,\n"," 'trap': 864,\n"," 'moran': 865,\n"," 'charge': 866,\n"," 'break': 867,\n"," 'horrible': 868,\n"," 'horner': 869,\n"," 'gems': 870,\n"," 'bohemia': 871,\n"," 'pips': 872,\n"," 'lip': 873,\n"," 'beeches': 874,\n"," 'results': 875,\n"," 'complete': 876,\n"," 'keen': 877,\n"," 'deeply': 878,\n"," 'following': 879,\n"," 'official': 880,\n"," 'practice': 881,\n"," 'tall': 882,\n"," 'lived': 883,\n"," \"can't\": 884,\n"," 'often': 885,\n"," 'interested': 886,\n"," 'sheet': 887,\n"," 'writing': 888,\n"," 'precisely': 889,\n"," 'pair': 890,\n"," 'fifty': 891,\n"," \"there's\": 892,\n"," 'raised': 893,\n"," 'chin': 894,\n"," 'honour': 895,\n"," 'state': 896,\n"," 'passing': 897,\n"," 'purpose': 898,\n"," 'subject': 899,\n"," 'pretty': 900,\n"," 'inquiry': 901,\n"," 'investigation': 902,\n"," 'ill': 903,\n"," 'reach': 904,\n"," 'streets': 905,\n"," 'law': 906,\n"," 'action': 907,\n"," 'cigar': 908,\n"," 'number': 909,\n"," 'knows': 910,\n"," 'carry': 911,\n"," 'blow': 912,\n"," 'draw': 913,\n"," 'perfectly': 914,\n"," 'precious': 915,\n"," 'wonder': 916,\n"," 'broken': 917,\n"," 'wished': 918,\n"," 'possibly': 919,\n"," 'narrative': 920,\n"," 'real': 921,\n"," 'west': 922,\n"," 'statement': 923,\n"," 'human': 924,\n"," \"'no\": 925,\n"," 'piece': 926,\n"," 'beg': 927,\n"," 'lawn': 928,\n"," 'shining': 929,\n"," 'merryweather': 930,\n"," 'iron': 931,\n"," 'lens': 932,\n"," 'kept': 933,\n"," 'weary': 934,\n"," 'worn': 935,\n"," 'alive': 936,\n"," 'firm': 937,\n"," 'traces': 938,\n"," 'free': 939,\n"," 'looks': 940,\n"," 'trouble': 941,\n"," 'horror': 942,\n"," 'sometimes': 943,\n"," 'grew': 944,\n"," 'opium': 945,\n"," 'lascar': 946,\n"," 'madam': 947,\n"," 'bradstreet': 948,\n"," 'orange': 949,\n"," 'reasoning': 950,\n"," 'drawing': 951,\n"," 'throw': 952,\n"," 'beyond': 953,\n"," 'returning': 954,\n"," 'hot': 955,\n"," 'post': 956,\n"," 'quarter': 957,\n"," 'wanted': 958,\n"," 'rich': 959,\n"," 'seat': 960,\n"," 'influence': 961,\n"," 'acquaintance': 962,\n"," 'opening': 963,\n"," 'beautiful': 964,\n"," 'handed': 965,\n"," 'briony': 966,\n"," 'dozen': 967,\n"," 'neighbourhood': 968,\n"," 'wind': 969,\n"," 'search': 970,\n"," 'fine': 971,\n"," 'contrary': 972,\n"," \"woman's\": 973,\n"," 'fall': 974,\n"," 'creature': 975,\n"," 'arm': 976,\n"," 'questioning': 977,\n"," 'evil': 978,\n"," 'value': 979,\n"," 'remark': 980,\n"," 'thrust': 981,\n"," 'fortune': 982,\n"," 'learn': 983,\n"," 'presume': 984,\n"," 'couple': 985,\n"," 'ways': 986,\n"," 'sake': 987,\n"," 'huge': 988,\n"," \"'it\": 989,\n"," 'exceedingly': 990,\n"," \"'yes\": 991,\n"," 'lad': 992,\n"," 'fingers': 993,\n"," 'jones': 994,\n"," 'scotland': 995,\n"," 'narrow': 996,\n"," 'unless': 997,\n"," 'curious': 998,\n"," 'connection': 999,\n"," 'plain': 1000,\n"," ...}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#declare ngrams\n","input_sequences = []\n","#split the sentence from '\\n'\n","for line in text.split('\\n'):\n","    #get tokens\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)"],"metadata":{"id":"oZyzz-zGwkdE","executionInfo":{"status":"ok","timestamp":1707551972044,"user_tz":-330,"elapsed":421,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["setence_token = input_sequences[3] # [1, 1561, 5, 129, 34]\n","sentence = []\n","for token in setence_token:\n","    sentence.append(list((tokenizer.word_index).keys())[list((tokenizer.word_index).values()).index(token)])\n","print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anu9sW8MwqOS","executionInfo":{"status":"ok","timestamp":1707551972045,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"13d3434f-9ad7-4a26-cc21-8b1e233cbb81"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'adventures', 'of', 'sherlock', 'holmes']\n"]}]},{"cell_type":"code","source":["#maximum sentence length\n","max_sequence_len = max([len(seq) for seq in input_sequences])\n","# input sequences\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"],"metadata":{"id":"Whuk_ZKVwtrz","executionInfo":{"status":"ok","timestamp":1707551972694,"user_tz":-330,"elapsed":661,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["X = input_sequences[:, :-1]\n","y = input_sequences[:, -1]"],"metadata":{"id":"XIGRJ3RrwyYb","executionInfo":{"status":"ok","timestamp":1707551972695,"user_tz":-330,"elapsed":16,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#convert one-hot-encode\n","y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"],"metadata":{"id":"kCr9BLyWw17e","executionInfo":{"status":"ok","timestamp":1707551974942,"user_tz":-330,"elapsed":2260,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#create model\n","model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(LSTM(150))\n","model.add(Dense(total_words, activation='softmax'))\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EogWCMgQw5MT","executionInfo":{"status":"ok","timestamp":1707551975368,"user_tz":-330,"elapsed":436,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"7921f6d4-7141-4d98-a020-72a7f5f352cd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 17, 100)           820000    \n","                                                                 \n"," lstm (LSTM)                 (None, 150)               150600    \n","                                                                 \n"," dense (Dense)               (None, 8200)              1238200   \n","                                                                 \n","=================================================================\n","Total params: 2208800 (8.43 MB)\n","Trainable params: 2208800 (8.43 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["#compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#fit the model\n","model.fit(X, y, epochs=100, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"049pTLg1w9Vc","executionInfo":{"status":"ok","timestamp":1707467919090,"user_tz":-330,"elapsed":10611403,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"77db5c33-a3d6-4065-9f22-57719931d620"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","3010/3010 [==============================] - 190s 62ms/step - loss: 6.2360 - accuracy: 0.0760\n","Epoch 2/100\n","3010/3010 [==============================] - 182s 60ms/step - loss: 5.5067 - accuracy: 0.1248\n","Epoch 3/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 5.1313 - accuracy: 0.1472\n","Epoch 4/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 4.8042 - accuracy: 0.1654\n","Epoch 5/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 4.5037 - accuracy: 0.1826\n","Epoch 6/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 4.2237 - accuracy: 0.2026\n","Epoch 7/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 3.9568 - accuracy: 0.2263\n","Epoch 8/100\n","3010/3010 [==============================] - 182s 61ms/step - loss: 3.7040 - accuracy: 0.2547\n","Epoch 9/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 3.4664 - accuracy: 0.2863\n","Epoch 10/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 3.2440 - accuracy: 0.3186\n","Epoch 11/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 3.0378 - accuracy: 0.3531\n","Epoch 12/100\n","3010/3010 [==============================] - 180s 60ms/step - loss: 2.8498 - accuracy: 0.3865\n","Epoch 13/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 2.6729 - accuracy: 0.4196\n","Epoch 14/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 2.5104 - accuracy: 0.4509\n","Epoch 15/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 2.3612 - accuracy: 0.4804\n","Epoch 16/100\n","3010/3010 [==============================] - 182s 61ms/step - loss: 2.2239 - accuracy: 0.5082\n","Epoch 17/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 2.0955 - accuracy: 0.5335\n","Epoch 18/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 1.9807 - accuracy: 0.5579\n","Epoch 19/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 1.8728 - accuracy: 0.5801\n","Epoch 20/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 1.7738 - accuracy: 0.6028\n","Epoch 21/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 1.6836 - accuracy: 0.6211\n","Epoch 22/100\n","3010/3010 [==============================] - 189s 63ms/step - loss: 1.5978 - accuracy: 0.6396\n","Epoch 23/100\n","3010/3010 [==============================] - 188s 62ms/step - loss: 1.5199 - accuracy: 0.6577\n","Epoch 24/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 1.4485 - accuracy: 0.6725\n","Epoch 25/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 1.3819 - accuracy: 0.6873\n","Epoch 26/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 1.3215 - accuracy: 0.7010\n","Epoch 27/100\n","3010/3010 [==============================] - 190s 63ms/step - loss: 1.2641 - accuracy: 0.7141\n","Epoch 28/100\n","3010/3010 [==============================] - 188s 62ms/step - loss: 1.2110 - accuracy: 0.7240\n","Epoch 29/100\n","3010/3010 [==============================] - 189s 63ms/step - loss: 1.1643 - accuracy: 0.7347\n","Epoch 30/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 1.1208 - accuracy: 0.7441\n","Epoch 31/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 1.0770 - accuracy: 0.7542\n","Epoch 32/100\n","3010/3010 [==============================] - 190s 63ms/step - loss: 1.0403 - accuracy: 0.7617\n","Epoch 33/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 1.0047 - accuracy: 0.7692\n","Epoch 34/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.9694 - accuracy: 0.7784\n","Epoch 35/100\n","3010/3010 [==============================] - 182s 61ms/step - loss: 0.9411 - accuracy: 0.7822\n","Epoch 36/100\n","3010/3010 [==============================] - 182s 60ms/step - loss: 0.9099 - accuracy: 0.7901\n","Epoch 37/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.8839 - accuracy: 0.7970\n","Epoch 38/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.8614 - accuracy: 0.8009\n","Epoch 39/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.8393 - accuracy: 0.8055\n","Epoch 40/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.8165 - accuracy: 0.8114\n","Epoch 41/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.7989 - accuracy: 0.8134\n","Epoch 42/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.7789 - accuracy: 0.8182\n","Epoch 43/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.7632 - accuracy: 0.8209\n","Epoch 44/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.7459 - accuracy: 0.8247\n","Epoch 45/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.7330 - accuracy: 0.8278\n","Epoch 46/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.7157 - accuracy: 0.8317\n","Epoch 47/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.7036 - accuracy: 0.8333\n","Epoch 48/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 0.6904 - accuracy: 0.8370\n","Epoch 49/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.6812 - accuracy: 0.8382\n","Epoch 50/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.6702 - accuracy: 0.8402\n","Epoch 51/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.6607 - accuracy: 0.8421\n","Epoch 52/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.6531 - accuracy: 0.8434\n","Epoch 53/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.6439 - accuracy: 0.8459\n","Epoch 54/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.6346 - accuracy: 0.8479\n","Epoch 55/100\n","3010/3010 [==============================] - 192s 64ms/step - loss: 0.6278 - accuracy: 0.8490\n","Epoch 56/100\n","3010/3010 [==============================] - 190s 63ms/step - loss: 0.6210 - accuracy: 0.8501\n","Epoch 57/100\n","3010/3010 [==============================] - 189s 63ms/step - loss: 0.6111 - accuracy: 0.8526\n","Epoch 58/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.6069 - accuracy: 0.8536\n","Epoch 59/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.6003 - accuracy: 0.8535\n","Epoch 60/100\n","3010/3010 [==============================] - 182s 61ms/step - loss: 0.5981 - accuracy: 0.8534\n","Epoch 61/100\n","3010/3010 [==============================] - 182s 60ms/step - loss: 0.5871 - accuracy: 0.8567\n","Epoch 62/100\n","3010/3010 [==============================] - 180s 60ms/step - loss: 0.5910 - accuracy: 0.8547\n","Epoch 63/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5778 - accuracy: 0.8579\n","Epoch 64/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5803 - accuracy: 0.8577\n","Epoch 65/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5711 - accuracy: 0.8587\n","Epoch 66/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5671 - accuracy: 0.8604\n","Epoch 67/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5657 - accuracy: 0.8593\n","Epoch 68/100\n","3010/3010 [==============================] - 180s 60ms/step - loss: 0.5673 - accuracy: 0.8578\n","Epoch 69/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5615 - accuracy: 0.8604\n","Epoch 70/100\n","3010/3010 [==============================] - 182s 60ms/step - loss: 0.5547 - accuracy: 0.8625\n","Epoch 71/100\n","3010/3010 [==============================] - 181s 60ms/step - loss: 0.5521 - accuracy: 0.8622\n","Epoch 72/100\n","3010/3010 [==============================] - 182s 60ms/step - loss: 0.5534 - accuracy: 0.8614\n","Epoch 73/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5473 - accuracy: 0.8621\n","Epoch 74/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5457 - accuracy: 0.8628\n","Epoch 75/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.5427 - accuracy: 0.8627\n","Epoch 76/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5410 - accuracy: 0.8638\n","Epoch 77/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 0.5392 - accuracy: 0.8640\n","Epoch 78/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 0.5354 - accuracy: 0.8648\n","Epoch 79/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5339 - accuracy: 0.8648\n","Epoch 80/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5340 - accuracy: 0.8638\n","Epoch 81/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.5282 - accuracy: 0.8659\n","Epoch 82/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5284 - accuracy: 0.8660\n","Epoch 83/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.5239 - accuracy: 0.8660\n","Epoch 84/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.5236 - accuracy: 0.8657\n","Epoch 85/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5200 - accuracy: 0.8676\n","Epoch 86/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.5202 - accuracy: 0.8664\n","Epoch 87/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.5212 - accuracy: 0.8664\n","Epoch 88/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5135 - accuracy: 0.8681\n","Epoch 89/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5119 - accuracy: 0.8688\n","Epoch 90/100\n","3010/3010 [==============================] - 183s 61ms/step - loss: 0.5179 - accuracy: 0.8669\n","Epoch 91/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.5194 - accuracy: 0.8654\n","Epoch 92/100\n","3010/3010 [==============================] - 184s 61ms/step - loss: 0.5109 - accuracy: 0.8679\n","Epoch 93/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.5164 - accuracy: 0.8645\n","Epoch 94/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.5135 - accuracy: 0.8667\n","Epoch 95/100\n","3010/3010 [==============================] - 185s 62ms/step - loss: 0.5145 - accuracy: 0.8659\n","Epoch 96/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.5075 - accuracy: 0.8688\n","Epoch 97/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5109 - accuracy: 0.8669\n","Epoch 98/100\n","3010/3010 [==============================] - 187s 62ms/step - loss: 0.5082 - accuracy: 0.8678\n","Epoch 99/100\n","3010/3010 [==============================] - 185s 61ms/step - loss: 0.5072 - accuracy: 0.8675\n","Epoch 100/100\n","3010/3010 [==============================] - 186s 62ms/step - loss: 0.5057 - accuracy: 0.8686\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b5dfb03baf0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#determine a text\n","seed_text = \"I fail to see\"\n","# predict word number\n","next_words = 5\n","\n","for _ in range(next_words):\n","    #convert to token\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    #path sequences\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    #model prediction\n","    predicted = np.argmax(loaded_model.predict(token_list), axis=-1)\n","    output_word = \"\"\n","    # get predict words\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word"],"metadata":{"id":"ajXKUu7SxCN0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707552439059,"user_tz":-330,"elapsed":664,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"8741d057-8a34-4190-8710-27fc6085f20b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]}]},{"cell_type":"code","source":["seed_text"],"metadata":{"id":"rhsibr1x6yWW","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1707552444108,"user_tz":-330,"elapsed":435,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"917e2680-21f0-4373-acd4-de474c5543af"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'I fail to see that anyone is to blame'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gt5mXZ9BI0I","executionInfo":{"status":"ok","timestamp":1707551846398,"user_tz":-330,"elapsed":35089,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"cea06dff-8064-4d34-9eb4-d8a65666d3f7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["model.save(\"/content/drive/MyDrive/model\")"],"metadata":{"id":"UiQsFX6QBcCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save(\"/content/drive/MyDrive/model/model.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3bGzt3X9CEM2","executionInfo":{"status":"ok","timestamp":1707468289470,"user_tz":-330,"elapsed":537,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}},"outputId":"7d076774-1820-497e-c31f-3348a6252705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","loaded_model = load_model('/content/drive/MyDrive/model/model.h5')"],"metadata":{"id":"cx7p4tiUCnD3","executionInfo":{"status":"ok","timestamp":1707551952306,"user_tz":-330,"elapsed":6393,"user":{"displayName":"Anusha Dixit","userId":"13421070721988091679"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RJoLZA4dBvGf"},"execution_count":null,"outputs":[]}]}